TODO:
DONE 1. Interface with nibabel (niftty lib) for easy reading data base
DONE 2. Convert data-base to like-mnist style, for easy reading with tensorflow
DONE 3. Create examples using random subsampling
DONE 4. Develop network code with tensorBoard

SubTasks:

dataCreator:
	DONE - 1. Add prints to dataCreator
	2. Add show option to dataCreator
	DONE - 3. Create meta data
	DONE - 4. Do the train/test division in the dataCreator step

shuffle:
	DONE - 1. Develop shuffle script

fileHandler:
	1. Handle the issue with the reshape blob

viewers:
	1. Create generic viewer
	2. Create viewer for trainin examples

Matlab:
	Run all interpolation methods for comparison

DataBase:
	DONE - 1. Create mnist-like data base with get_batch(50) method.

TensorFlow:
	1. Develop a network

General:
	1. Add run-form command line class, as I have in work

Data:
1. What is the best representation to imaeg & kspace
    image - int16
    k_space - currently float64 so real = image = float32

    k_space:
    The values are very small, but int is > 0 -> probably learn the network the log image
    save the factor in meta_data

2. Run histogram on real & image values of k-space in order to learn the mean & variancec.
   - Where is the information? around zero?? , if yes, when normalaize all data to be bigger than zero, we loosing the information

3. Crop image to 4 smaller images, 64x64, better for run-time.
  - What to do in the overlaps?

4. Data quantization: 
	- data -> log instead of real values
	- move to uint16 representation while zero is missing lines
	- Do inverse-furier of the image, and learn to complete the missing line in image-space
	- add normalaize to get_batch function
